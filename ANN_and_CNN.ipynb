{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN and CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPr71oOEIHn42pn2V3CvkJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cleysonl/Tensorflow2.0/blob/master/ANN_and_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMkAdfqXowa",
        "colab_type": "text"
      },
      "source": [
        "# **ANN with TF2.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGWvRnzShlC0",
        "colab_type": "code",
        "outputId": "0544383b-510b-4525-f741-c8e0814b4bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0.alpha0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n",
            "\u001b[K     |████████████████████████████████| 332.1MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.33.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 13.8MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190301 tensorflow-gpu-2.0.0a0 tf-estimator-nightly-1.14.0.dev2019030115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jON5df32k-jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTkqVU6JmizA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # or any {'0',' 1', '2'}\n",
        "\n",
        "def mnist_dataset():\n",
        "  (x,y),_ = tf.keras.datasets.mnist.load_data()\n",
        "  ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  ds = ds.map(prepare_mnist_features_and_labels)\n",
        "  ds = ds.take(20000).shuffle(20000).batch(100)\n",
        "  return ds\n",
        "\n",
        "def prepare_mnist_features_and_labels(x,y):\n",
        "  x = tf.cast(x, tf.float32)/255.\n",
        "  y = tf.cast(y, tf.int64)\n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs1XfaIQlSHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the model\n",
        "model = tf.keras.models.Sequential()\n",
        "# Define the layers\n",
        "model.add(tf.keras.layers.Reshape(target_shape=(28*28,),input_shape=(28,28)))\n",
        "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=100, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=10))\n",
        "#define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVssbUmir16f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss(logits, labels):\n",
        "  return tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=logits, labels=labels))\n",
        "\n",
        "@tf.function\n",
        "def compute_accuracy(logits, labels):\n",
        "  predictions = tf.argmax(logits, axis=1)\n",
        "  return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32)) \n",
        "\n",
        "@tf.function\n",
        "def train_one_step(model, optimizer, x, y):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(x)\n",
        "    loss = compute_loss(logits, y)\n",
        "\n",
        "    #compute gradient\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    #update weights\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    accuracy = compute_accuracy(logits, y)\n",
        "\n",
        "    #loss and accuracy is scalar tensor\n",
        "    return loss, accuracy\n",
        "\n",
        "def train(epoch, model, optimizer):\n",
        "  train_ds = mnist_dataset()\n",
        "  loss = 0.0\n",
        "  accuracy = 0.0\n",
        "  for step, (x,y) in enumerate(train_ds):\n",
        "    loss, accuracy = train_one_step(model, optimizer, x, y)\n",
        "\n",
        "    if step%500 == 0:\n",
        "      print('epoch', epoch, ':loss', loss.numpy(), ': accuracy', accuracy.numpy())\n",
        "\n",
        "  return loss, accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiaOjS9B1dGz",
        "colab_type": "code",
        "outputId": "033c9d96-aeac-4ca5-cfe3-2eb4ef99e2b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for epoch in range(20):\n",
        "  loss, accuracy = train(epoch, model, optimizer)\n",
        "\n",
        "print('Final epoch', epoch, ': loss', loss.numpy(), '; accuracy', accuracy.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 :loss 2.3029244 : accuracy 0.13\n",
            "epoch 1 :loss 0.16009605 : accuracy 0.95\n",
            "epoch 2 :loss 0.17455128 : accuracy 0.95\n",
            "epoch 3 :loss 0.086833164 : accuracy 0.98\n",
            "epoch 4 :loss 0.09488362 : accuracy 0.96\n",
            "epoch 5 :loss 0.037679218 : accuracy 1.0\n",
            "epoch 6 :loss 0.049664084 : accuracy 0.98\n",
            "epoch 7 :loss 0.029889045 : accuracy 1.0\n",
            "epoch 8 :loss 0.008005618 : accuracy 1.0\n",
            "epoch 9 :loss 0.028494503 : accuracy 0.99\n",
            "epoch 10 :loss 0.013228629 : accuracy 1.0\n",
            "epoch 11 :loss 0.01597538 : accuracy 1.0\n",
            "epoch 12 :loss 0.00436632 : accuracy 1.0\n",
            "epoch 13 :loss 0.0071314042 : accuracy 1.0\n",
            "epoch 14 :loss 0.007745029 : accuracy 1.0\n",
            "epoch 15 :loss 0.0046918783 : accuracy 1.0\n",
            "epoch 16 :loss 0.004132434 : accuracy 1.0\n",
            "epoch 17 :loss 0.0023726213 : accuracy 1.0\n",
            "epoch 18 :loss 0.003863144 : accuracy 1.0\n",
            "epoch 19 :loss 0.0038915456 : accuracy 1.0\n",
            "Final epoch 19 : loss 0.0015582936 ; accuracy 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xq5hRsh1kf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEDQidO1Xusy",
        "colab_type": "text"
      },
      "source": [
        "#**CNN with TF2.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-t8-0wxXyUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import summary_ops_v2\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, optimizers, metrics\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loGxDJ26c-gT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "77c917ae-e7b8-4152-e73c-87f0ca398fce"
      },
      "source": [
        "def mnist_dataset():\n",
        "  (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "  X_train, X_test = X_train/np.float32(255), X_test/np.float32(255)\n",
        "  y_train, y_test = y_train.astype(np.int64), y_test.astype(np.int64)\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "train_ds, test_ds = mnist_dataset()\n",
        "train_ds = train_ds.shuffle(60000).batch(100)\n",
        "test_ds = test_ds.batch(100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrkEJK3Rffkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Reshape(target_shape=[28,28,1], input_shape=(28, 28,)))\n",
        "model.add(layers.Conv2D(filters = 2, kernel_size = 5,padding='same', activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2,2), strides= (2,2), padding='same',))\n",
        "model.add(layers.Conv2D(filters = 4, kernel_size = 5, padding ='same'))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2,2), strides= (2,2), padding='same',))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units = 32, activation='relu'))\n",
        "model.add(layers.Dropout(rate=0.4))\n",
        "model.add(layers.Dense(units=10))\n",
        "\n",
        "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "compute_accuracy = tf.keras.metrics.SparseTopKCategoricalAccuracy()\n",
        "optimizer = optimizers.SGD(learning_rate=0.01, momentum = 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcIyHNJBiiPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, optimizer, images, labels):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    logits = model(images, training=True)\n",
        "    loss = compute_loss(labels, logits)\n",
        "    compute_accuracy(labels, logits)\n",
        "\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  \n",
        "  return loss\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}